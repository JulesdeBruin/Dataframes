{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store ID Location  Employees\n",
      "0         1       SD        100\n",
      "1         2       LA        120\n",
      "2         3       SF         90\n",
      "3         4        S        115\n",
      "   Store ID       Location  Number of Employees\n",
      "0         1      San Diego                  100\n",
      "1         2    Los Angeles                  120\n",
      "2         3  San Francisco                   90\n",
      "3         4     Sacramento                  115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1 = pd.DataFrame({\n",
    "    \"Store ID\": [1,2,3,4],\n",
    "    \"Location\": [\"SD\", \"LA\", \"SF\", \"S\"],\n",
    "    \"Employees\": [100, 120, 90, 115]\n",
    "})\n",
    "\n",
    "print(df1)\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "  'Product ID': [1, 2, 3, 4],\n",
    "  'Product Name': [\"t-shirt\", \"t-shirt\", \"skirt\", \"skirt\"],\n",
    "  'Color': [\"blue\", \"green\", \"red\", \"black\"]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame([\n",
    "  [1, 'San Diego', 100],\n",
    "  [2, 'Los Angeles', 120],\n",
    "  [3, 'San Francisco', 90],\n",
    "  [4, 'Sacramento', 115]# Fill in rows 3 and 4\n",
    "],\n",
    "  columns=['Store ID', 'Location', 'Number of Employees'\n",
    "  ])\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'my-csv-file.csv' does not exist: b'my-csv-file.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-be37b3e931d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my-csv-file.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new-csv-file.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'my-csv-file.csv' does not exist: b'my-csv-file.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv('my-csv-file.csv')\n",
    "df.to_csv('new-csv-file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"imdb.csv\")\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_north = df[\"clinic_north\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_north_south = df[[\"clinic_north\", \"clinic_south\"]]\n",
    "print(type(clinic_north_south))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "march = df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age == 30]\n",
    "january = df[df.month == \"January\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.age < 30) |\n",
    "   (df.name == 'Martha Jones')]\n",
    "\"\"\"\n",
    "In Python, | means “or” and & means “and”.\n",
    "\"\"\"\n",
    "march_april = df[(df.month == \"March\") | (df.month == \"April\")]\n",
    "\n",
    "#vergeet logical statements niet tussen haakjes te zetten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.name.isin(['Martha Jones',\n",
    "     'Rose Tyler',\n",
    "     'Amy Pond'])]\n",
    "\n",
    "january_february_march = df[df.month.isin([\"January\", \"February\", \"March\"])]\n",
    "\n",
    "print(january_february_march)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[[1, 3, 5]]\n",
    "\n",
    "# print(df2)\n",
    "\n",
    "df3 = df2.reset_index()\n",
    "\n",
    "print(df3)\n",
    "\n",
    "df2.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib\n",
    "import pandas as pd\n",
    "\n",
    "orders = pd.read_csv(\"shoefly.csv\")\n",
    "print(orders.head())\n",
    "\n",
    "emails = orders[\"email\"]\n",
    "\n",
    "frances_palmer = orders[(orders.first_name == \"Frances\") & (orders.last_name == \"Palmer\")]\n",
    "\n",
    "print(frances_palmer)\n",
    "\n",
    "comfy_shoes = orders[(orders.shoe_type == \"clogs\") | (orders.shoe_type == \"boots\") | (orders.shoe_type == \"ballet flats\")]\n",
    "\n",
    "print(comfy_shoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column\n",
    "df[\"Sold in Bulk?\"] = [\"Yes\", \"Yes\", \"No\", \"No\"]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Suppose we know that all of our products are currently in-stock. \n",
    "We can add a column that says this:\n",
    "\"\"\"\n",
    "\n",
    "df['In Stock?'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Margin\"] = df[\"Price\"] - df[\"Cost to Manufacture\"]\n",
    "\"\"\"\n",
    "You’ll need to access the values of Cost to Manufacture using \n",
    "df['Cost to Manufacture'] because the column name \n",
    "doesn’t follow our rules for variable names.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can use the apply function to apply a function to every \n",
    "value in a particular column. For example, this code overwrites the \n",
    "existing 'Name' columns by applying \n",
    "the function upper to every row in 'Name'.\"\"\"\n",
    "from string import upper\n",
    "\n",
    "df['Name'] = df.Name.apply(upper)\n",
    "#---------\n",
    "df[\"Lowercase Name\"] = df.Name.apply(lower)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringlambda = lambda x: x.lower()\n",
    "print(stringlambda(\"Oh Hi Mark!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylambda = lambda x: x[0] + x[-1]\n",
    "print(mylambda(\"Hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunction = lambda x: 40 + (x - 40) * 1.50 if x > 40 else x\n",
    "lambda x: [OUTCOME IF TRUE] if [CONDITIONAL] else [OUTCOME IF FALSE]\n",
    "mylambda = lambda x: \"Welcome to BattleCity!\" if x >= 13 else \"You must be over 13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Email Provider'] = df.Email.apply(\n",
    "    lambda x: x.split('@')[-1]\n",
    "    )\n",
    "#----\n",
    "get_last_name = lambda x: x.split(\" \")[-1]\n",
    "df[\"last_name\"] = df.name.apply(get_last_name)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price with Tax'] = df.apply(lambda row:\n",
    "     row['Price'] * 1.075\n",
    "     if row['Is taxed?'] == 'Yes'\n",
    "     else row['Price'],\n",
    "     axis=1\n",
    ")\n",
    "\n",
    "#We can create this column using a lambda function and the keyword axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_earned = lambda row: (row.hourly_wage * 40) + ((row.hourly_wage * 1.5) * (row.hours_worked - 40)) \\\n",
    "\tif row.hours_worked > 40 \\\n",
    "  else row.hourly_wage * row.hours_worked\n",
    "  \n",
    "df['total_earned'] = df.apply(total_earned, axis = 1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"First Name\", \"Age\"]\n",
    "# Rename columns here\n",
    "df.columns = [\"ID\", \"Title\", \"Category\", \"Year Released\", \"Rating\"]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You also can rename individual columns by using the .rename method. \n",
    "Pass a dictionary like the one below to the columns keyword argument:\"\"\"\n",
    "df = pd.DataFrame({\n",
    "    'name': ['John', 'Jane', 'Sue', 'Fred'],\n",
    "    'age': [23, 29, 21, 18]\n",
    "})\n",
    "df.rename(columns={\n",
    "    'name': 'First Name',\n",
    "    'age': 'Age'},\n",
    "    inplace=True)\n",
    "\n",
    "# Rename columns here\n",
    "df.rename(columns=\n",
    "  {\n",
    "    \"name\": \"movie_title\"},\n",
    "    inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['shoe_source'] = orders.shoe_material.apply(lambda x: \\\n",
    "                        \t'animal' if x == 'leather'else 'vegan')\n",
    "\n",
    "orders['salutation'] = orders.apply(lambda row: \\\n",
    "                                    'Dear Mr. ' + row['last_name']\n",
    "                                    if row['gender'] == 'male'\n",
    "                                    else 'Dear Ms. ' + row['last_name'],\n",
    "                                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "inventory = pd.read_csv(\"inventory.csv\")\n",
    "print(inventory.head(10))\n",
    "staten_island = inventory.head(10)\n",
    "\n",
    "\n",
    "staten_island[\"product_request\"] = staten_island[\"product_description\"]\n",
    "\n",
    "seed_request = inventory[(inventory[\"location\"] == \"Brooklyn\") & (inventory[\"product_type\"] == \"seeds\")]\n",
    "\n",
    "inventory[\"in_stock\"] = inventory.apply(lambda row: True if (row[\"quantity\"] > 0) else False, axis=1)\n",
    "\n",
    "inventory[\"total_value\"] =inventory.apply(lambda row: row.price * row.quantity, axis=1)\n",
    "\n",
    "print(inventory.head(10))\n",
    "\n",
    "combine_lambda = lambda row: \\\n",
    "    '{} - {}'.format(row.product_type,\n",
    "                     row.product_description)\n",
    "\n",
    "inventory[\"full_description\"] = inventory.apply(combine_lambda, axis=1)\n",
    "\n",
    "print(inventory.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we analyze anything, we need to import pandas\n",
    "# and load our data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('shoefly_page_visits.csv')\n",
    "\n",
    "# This command shows us how many users visited the site from different sources in different months.\n",
    "df.groupby(['month', 'utm_source']).id.count().reset_index()\n",
    "\n",
    "# This command shows us how many users visited the site from different sources in different months.\n",
    "df.groupby(['month', 'utm_source']).id.count()\\\n",
    "    .reset_index()\\\n",
    "    .pivot(columns='month', index='utm_source', values='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customers.age)\n",
    ">> [23, 25, 31, 35, 35, 46, 62]\n",
    "print(customers.age.median())\n",
    ">> 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shipments.state)\n",
    ">> ['CA', 'CA', 'CA', 'CA', 'NY', 'NY', 'NJ', 'NJ', 'NJ', 'NJ', 'NJ', 'NJ', 'NJ']\n",
    "print(shipments.state.nunique())\n",
    ">> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inventory.color)\n",
    ">> ['blue', 'blue', 'blue', 'blue', 'blue', 'green', 'green', 'orange', 'orange', 'orange']\n",
    "print(inventory.color.unique())\n",
    ">> ['blue', 'green', 'orange']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General syntax for these calculations\n",
    "## df.column_name.command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_expensive = orders.price.max()\n",
    "number_of_colors = orders.shoe_color.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = df.groupby('student').grade.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('column1').column2.measurement()\n",
    "#column1 is the column that we want to group by ('student' in our example)\n",
    "#column2 is the column that we want to perform a measurement on (grade in our example)\n",
    "#measurement is the measurement function we want to apply (mean in our example)\n",
    "\n",
    "pricey_shoes= orders.groupby(\"shoe_type\").price.max()\n",
    "\n",
    "print(pricey_shoes)\n",
    "\n",
    "print(type(pricey_shoes))\n",
    "\n",
    "pricey_shoes = orders.groupby(\"category\").price.max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usually, we’d prefer that those indices were actually a column. \n",
    "#In order to get that, we can use reset_index(). This will transform \n",
    "#our Series into a DataFrame and move the indices into their own column.\n",
    "#generally you'll always see something like this\n",
    "df.groupby('column1').column2.measurement()\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teas_counts = teas.groupby('category').id.count().reset_index()\n",
    "\n",
    "teas_counts = teas.groupby(\"category\").id.count().reset_index()\n",
    "\n",
    "teas_counts = teas_counts.rename(columns={\"id\": \"counts\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.percentile can calculate any percentile over an array of values\n",
    "high_earners = df.groupby('category').wage\n",
    "    .apply(lambda x: np.percentile(x, 75))\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheap_shoes = orders.groupby(\"shoe_color\").price.apply(lambda x: np.percentile(x,25)).reset_index()\n",
    "\n",
    "print(cheap_shoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Location', 'Day of Week'])['Total Sales'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_counts = orders.groupby(['shoe_type', 'shoe_color']).id.count().reset_index()\n",
    "\n",
    "print(shoe_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(columns='ColumnToPivot',\n",
    "         index='ColumnToBeRows',\n",
    "         values='ColumnToBeValues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First use the groupby statement:\n",
    "unpivoted = df.groupby(['Location', 'Day of Week'])['Total Sales'].mean().reset_index()\n",
    "# Now pivot the table\n",
    "pivoted = unpivoted.pivot(\n",
    "    columns='Day of Week',\n",
    "    index='Location',\n",
    "    values='Total Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_counts_pivot = shoe_counts.pivot(columns = \"shoe_color\", index = \"shoe_type\", values=\"id\").reset_index()\n",
    "\n",
    "print(shoe_counts_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib\n",
    "import pandas as pd\n",
    "\n",
    "user_visits = pd.read_csv('page_visits.csv')\n",
    "\n",
    "\n",
    "print(user_visits.head())\n",
    "\n",
    "click_source = user_visits.groupby([\"utm_source\"]).id.count().reset_index()\n",
    "\n",
    "print(click_source)\n",
    "\n",
    "click_source_by_month = user_visits.groupby([\"utm_source\", \"month\"]).id.count().reset_index()\n",
    "\n",
    "click_source_by_month_pivot = click_source_by_month.pivot(columns=\"month\", index=\"utm_source\", values=\"id\").reset_index()\n",
    "\n",
    "print(click_source_by_month_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkouts.groupby([\"book_title\"])[\"location\"].count().reset_index()\n",
    "# => this will count the number of locations that each book title has \n",
    "# been checked out from, which is not what we want to determine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib\n",
    "import pandas as pd\n",
    "\n",
    "ad_clicks = pd.read_csv('ad_clicks.csv')\n",
    "\n",
    "print(ad_clicks.head())\n",
    "\n",
    "amout_of_views = ad_clicks.groupby(\"utm_source\").count().reset_index()\n",
    "\n",
    "print(amout_of_views.head())\n",
    "\n",
    "ad_clicks[\"is_click\"] = ~ad_clicks.ad_click_timestamp.isnull()\n",
    "\n",
    "print(ad_clicks.head())\n",
    "\n",
    "clicks_by_source = ad_clicks.groupby([\"utm_source\", \"is_click\"]).user_id.count()\n",
    "\n",
    "clicks_pivot = ad_clicks.pivot(columns=\"is_click\", index=\"utm_source\", values=\"user_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib\n",
    "import pandas as pd\n",
    "\n",
    "sales = pd.read_csv('sales.csv')\n",
    "print(sales)\n",
    "targets = pd.read_csv('targets.csv')\n",
    "print(targets)\n",
    "\n",
    "sales_vs_targets = pd.merge(sales,targets)\n",
    "print(sales_vs_targets)\n",
    "\n",
    "crushing_it = sales_vs_targets[sales_vs_targets.revenue > sales_vs_targets.target]\n",
    "\n",
    "print(crushing_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In addition to using pd.merge, each DataFrame has its own merge method. \n",
    "#For instance, if you wanted to merge orders with customers, you could use:\n",
    "\n",
    "new_df = orders.merge(customers)\n",
    "# => This produces the same DataFrame as if we had called pd.merge(orders, customers)\n",
    "\n",
    "#We generally use this when we are joining more than two DataFrames together \n",
    "#because we can “chain” the commands. The following command would merge orders to \n",
    "#customers, and then the resulting DataFrame to products:\n",
    "\n",
    "big_df = orders.merge(customers)\\\n",
    "    .merge(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = sales.merge(targets)\\\n",
    "  .merge(men_women)\n",
    "\n",
    "print(all_data)\n",
    "\n",
    "results = all_data[(all_data.revenue > all_data.target) & (all_data.women > all_data.men)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    orders,\n",
    "    customers.rename(columns={'id': 'customer_id'}))\n",
    "orders_products = pd.merge(\n",
    "  orders,\n",
    "  products.rename(columns={\"id\":\"product_id\"})\n",
    ")\n",
    "\n",
    "print(orders_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    orders,\n",
    "    customers,\n",
    "    left_on='customer_id',\n",
    "    right_on='id',\n",
    "    suffixes=['_order', '_customer']\n",
    ")\n",
    "#Any missing values are filled in with None or \n",
    "#nan (which stands for “Not a Number”).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(company_a, company_b, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_a_b_left = pd.merge(store_a, store_b, how=\"left\")\n",
    "\n",
    "store_b_a_left = pd.merge(store_b, store_a, how=\"left\")\n",
    "\n",
    "print(store_a_b_left)\n",
    "print(store_b_a_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "When we need to reconstruct a single DataFrame from multiple \n",
    "smaller DataFrames, we can use the method pd.concat([df1, df2, df2, ...])\n",
    ". This method only works if all of the columns are the same in all \n",
    "of the DataFrames.\"\"\"\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = pd.read_csv('visits.csv',\n",
    "                        parse_dates=[1])\n",
    "checkouts = pd.read_csv('checkouts.csv',\n",
    "                        parse_dates=[1])\n",
    "\n",
    "print(visits)\n",
    "print(checkouts)\n",
    "\n",
    "v_to_c = pd.merge(visits, checkouts, how=\"left\")\n",
    "v_to_c[\"time\"] = v_to_c.checkout_time - v_to_c.visit_time\n",
    "\n",
    "\n",
    "print(v_to_c.time.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib\n",
    "import pandas as pd\n",
    "\n",
    "visits = pd.read_csv('visits.csv',\n",
    "                     parse_dates=[1])\n",
    "cart = pd.read_csv('cart.csv',\n",
    "                   parse_dates=[1])\n",
    "checkout = pd.read_csv('checkout.csv',\n",
    "                       parse_dates=[1])\n",
    "purchase = pd.read_csv('purchase.csv',\n",
    "                       parse_dates=[1])\n",
    "\n",
    "print(visits.head())\n",
    "print(cart.head())\n",
    "print(checkout.head())\n",
    "print(purchase.head())\n",
    "\n",
    "visits_cart = pd.merge(\n",
    "  visits,\n",
    "  cart,\n",
    "  how=\"left\"\n",
    ")\n",
    "\n",
    "print(visits_cart)\n",
    "visits_cart_rows = len(visits_cart)\n",
    "print(visits_cart_rows)\n",
    "\n",
    "null_cart_times = len(visits_cart[visits_cart.cart_time.isnull()])\n",
    "print(null_cart_times)\n",
    "\n",
    "print(float(null_cart_times) / visits_cart_rows)\n",
    "\n",
    "cart_checkout = pd.merge(cart, checkout, how=\"left\")\n",
    "print(cart_checkout)\n",
    "\n",
    "cart_checkout_rows = len(cart_checkout)\n",
    "null_checkout_times = cart_checkout[cart_checkout.checkout_time.isnull()]\n",
    "\n",
    "#print(float(null_checkout_times) / cart_checkout_rows)\n",
    "\n",
    "checkout_purchase = pd.merge(checkout, purchase, how=\"left\")\n",
    "checkout_purchase_rows = len(checkout_purchase)\n",
    "null_purchase_times = len(checkout_purchase[checkout_purchase.purchase_time.isnull()])\n",
    "\n",
    "print(float(null_purchase_times) / checkout_purchase_rows)\n",
    "\n",
    "\n",
    "all_data = visits\\\n",
    "  .merge(cart, how=\"left\")\\\n",
    "  .merge(checkout, how=\"left\")\\\n",
    "  .merge(purchase, how=\"left\")\n",
    "print(all_data.head())\n",
    "\n",
    "all_data['time_to_purchase'] = \\\n",
    "    all_data.purchase_time - \\\n",
    "    all_data.visit_time\n",
    "    \n",
    "print(all_data.time_to_purchase)\n",
    "print(all_data.time_to_purchase.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
